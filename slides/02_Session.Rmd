---
title: "<strong>Session 2:</strong> </br> Application of Monte Carlo simulation and Markov Chain Monte Carlo in PBPK modeling"
subtitle: "<html><div style='float:left'></div><hr color='#500000' size=1px width=796px></html>"
author: ".font125[Nan-Hung Hsieh, PhD] </br> Postdoc @ Texas A&M Superfund Decision Science Core"
institute: ""
date: "12/09/2019"
output:
  xaringan::moon_reader:
    includes:
      after_body: insert-logo.html
    css: [default, "tamu.css"]
    nature:
      ratio: '16:9'
      beforeInit: "macros.js"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('..')
wd <- getwd()
knitr::opts_knit$set(root.dir =  wd)
```

```{r, include=FALSE}
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
library(sensitivity)
library(simuloR)
library(dplyr)
```

# Deterministic vs Probabilistic

## Traditional - Deterministic

.font200[
**Choose the "specific" value (or the most conservative scenario) in the risk assessment**

.right[.bolder[Is it good enough?]]
]

---

# Deterministic vs Probabilistic

.pull-left[
## Traditional - Deterministic

.font200[
Choose the "specific" value (or the most conservative scenario) in the risk assessment
]
]

.pull-right[

## Modern - Probabilistic

.font200[
Combine "all" information and characterize the **uncertainty**
]
]

---

# Uncertainty in Risk Analysis

.font150[
The objective of a **probabilistic risk analysis** is the quantification of risk from made man-made and natural activities ([Vesely and Rasmuson, 1984](https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.1984.tb00950.x)).  
]

**Two major types of uncertainty need to be differentiated:**

### (1) Uncertainty due to physical variability

### (2) Uncertainty due to lack of knowledge in

.font125[
- Modeling uncertainty

- Parameter uncertainty

- Completeness uncertainty
]

---


# Monte Carlo Simulation

.font125[
- A method of estimating the value of unknown quantity using the principle of inferential statistics
- Inferential statistics
  - **Population**: Universal information
  - **Sample**: a proper subset of population
- .bolder[Repeatedly Random Sampling]
]

.pull-left[
.pull-left[<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/STAN_ULAM_HOLDING_THE_FERMIAC.jpg/300px-STAN_ULAM_HOLDING_THE_FERMIAC.jpg" height="220px" />  
Stanislaw Ulam  
]
.pull-right[<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/JohnvonNeumann-LosAlamos.gif/220px-JohnvonNeumann-LosAlamos.gif" height="220px" />  
John von Neumann
]
]

.pull-right[
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/ENIAC_Penn1.jpg/1280px-ENIAC_Penn1.jpg" height="220px" />  
ENIAC (Electronic Numerical Integrator and Computer)
]

---

# Uncertainty in modeling

### Deterministic Simulation

- Define exposure unit & calculate point estimate

### 1-D Monte Carlo Simulation: Uncertainty

- Identify probability distributions to simulate probabilistic outputs

### 2-D Monte Carlo Simulation: Uncertainty & Variability

- Bayesian statistics to characterize population uncertainty and variability

---

background-image: url(http://sci.tea-nifty.com/photos/uncategorized/2012/07/28/elephant.gif)
background-size: 240px
background-position: 50% 90% 

# Uncertainty in parameter

- **The parameter** is an element of a system that determine the model output. 

- **Parameter uncertainty** comes from the model parameters that are inputs to the mathematical model but whose exact values are unknown and cannot be controlled in physical experiments. 

$$y = f(x_i) $$

</br></br>

.pull-left[
> With four parameters I can fit an elephant, and with five I can make him wiggle his trunk. 
>
> -John von Neumann
]
.pull-right[

]

.footnote[Mayer J, Khairy K, Howard J. Drawing an elephant with four complex parameters. Am. J. Phys. 78, 648 (2010) https://doi.org/10.1119/1.3254017]


---

background-image: url(https://i.ibb.co/JB7s1bK/Screenshot-from-2019-09-24-11-49-47.png)
background-size: 700px
background-position: 50% 80% 

# Modeling in Risk Assessment  

.footnote[https://www.epa.gov/risk/about-risk-assessment#whatisrisk]

---

background-image: url(https://i.ibb.co/SmNTtv2/WHO.png)
background-size: 260px
background-position: 80% 90% 

# Uncertainty vs. Variability

.font150[

> **Uncertainty** relates to "lack of knowledge"" that, in theory, could be reduced by better data, whereas **variability** relates to an existing aspect of the real world that is outside our control.

> [*World Health Organization (2017)*](https://www.who.int/ipcs/methods/harmonization/areas/hazard_assessment/en/)

]

???

There is a clear definition to differentiate the uncertainty and variability in WHO document.

---

background-image: url()
background-size: 200px
background-position: 80% 80% 

# Variability in Risk Assessment

- Reduce chances using a strain that is a "poor" model of humans 
- Obtaining information about "potential range" to inform risk assessment 

.center[
![:scale 60%](https://i.ibb.co/ykYp8BY/variability.png)
]

.font75[Chiu WA and Rusyn I, 2018. https://doi.org/10.1007/s00335-017-9731-6]

---

### Variability & Uncertainty

.center[
![:scale 70%](https://i.ibb.co/Kq4nStY/Screen-Shot-2019-05-08-at-7-25-22-AM.png)
]

.footnote[
https://cran.r-project.org/web/packages/mc2d/index.html
]

---


# Uncertainty in PBPK model parameter

</br>

.pull-left[
**Physiological parameters**

Cardiac output

Blood flow rate

Tissue volume

]

.pull-right[

**Absorption**

Absorption fraction, absorption rate, ...

**Distribution**

Partition coefficient, distribution fraction, ... 

**Metabolism**

Michaelis–Menten kinetics, ...

**Elimination**

First order elimination rate, ...

]

---

class: middle

.font200[
In PK modeling...

We can conduct **Monte Carlo simulation** to quantify the possible outcomes (concentration).

But, in some cases,  

we might want know which parameter have high (or no) **"impact"** on model output

]

---

background-image: url(https://i.ibb.co/dcm90HB/Screen-Shot-2019-04-30-at-8-48-27-PM.png)
background-size: 760px
background-position: 50% 90% 

# Uncertainty & sensitivity analysis

---

# Sensitivity Analysis

.font150[
> "The study of how uncertainty in the output of a model (numerical or otherwise) can be apportioned to different sources of uncertainty in the model input." 

]

![:scale 90%](https://i.ibb.co/0smnKjL/SA.png)

.footnote[
Img: Krishnan, K. and Andersen, M.E. eds., 2010. Quantitative modeling in toxicology. John Wiley & Sons.
]

---

# Why we need SA?

### Parameter Prioritization

- Identify the most important factors

- Adjust the uncertainty in the model response in experiment design

### Parameter Fixing

- Identify the least important factors

- Simplify the model if it has too many factors

### Parameter Mapping

- Identify critical regions of the inputs that are responsible for extreme values of the model response

---

background-image: url(https://i.ibb.co/30S1XtS/Screen-Shot-2019-04-30-at-9-10-08-PM.png)
background-size: contain
background-position: 70% 10% 

# SA in experiment design

.footnote[
https://doi.org/10.1002/psp4.6
]

???

It consequently provides useful insight into which model input contributes most to the variability of the model output

---

# Classification of SA Methods

.footnote[http://evelynegroen.github.io]

.pull-left[

**Local** (One-at-a-time)

<img src="http://evelynegroen.github.io/assets/images/fig11local.jpg" height="240px" />

**"Local"** SA focus on sensitivity at a particular set of input parameters, usually using gradients or partial derivatives

]


???
Usually, some people have experience in modeling they have the knowledge in local sensitivity analysis. 

This method is very simple. You move one parameter and fix other parameters then check the change of model outputs. 

On the other side, some researcher also developed the approach that moves all parameters at a time and checks the change of model output. We call it Global sensitivity analysis or variance-based sensitivity analysis.

--

.pull-right[

**Global** (All-at-a-time)

<img src="http://evelynegroen.github.io/assets/images/fig2global.jpg" height="240px" />

**"Global"** SA calculates the contribution from the variety of all model parameters, including .bolder[Single parameter effects] and .bolder[Multiple parameter interactions]

]

???

Usually, some people have experience in modeling they have the knowledge in local sensitivity analysis.

This method is very simple. You move one parameter and fix other parameters then check the change of model outputs.

On the other side, some researcher also developed the approach that moves all parameters at a time and checks the change of model output. We call it Global sensitivity analysis or variance-based sensitivity analysis.

---

# Sensitivity indices

.font120[First order] $(S_i)$

- The output variance contributed by the specific parameter $x_i$,  
also known as .bolder[main effect]

.font120[Interaction] $(S_{ij})$

- The output variance contributed by any non-identical pair of input parameters

.font120[Total order] $(S_{T})$

- The output variance contributed by the specific parameter and interaction,  
also known as .bolder[total effect]


<hr/>

.left[
**“Local”** SA usually only addresses first order effects

**“Global”** SA can address total effect that include main effect and interaction
]

---

# Variance-Based Method

- Variance-based method for sensitivity analysis were first employed by chemists ([Cukier et al. 1973](http://scitation.aip.org/content/aip/journal/jcp/59/8/10.1063/1.1680571)). The method, known as **FAST** (Fourier Amplitude Sensitivity Test). 

- Robust in **factor fixing**, but had relatively high computational cost than local SA.

### Main effect

$$S_{i}=\frac{V\left[E\left(Y | X_{i}\right)\right]}{V(Y)}$$

</br>

### Total effect
Example of parameter 1 for model with three parameters

$$S_{T 1}=S_{1}+S_{12}+S_{13}+S_{123}$$

$$S_{1}+ S_2 + S_{3} + S_{12}+S_{13} + S_{23} + S_{123} = 1$$

---

# Project

Funding: Food and Drug Administration (1U01FD005838)

Project Start: Sep-2016

Name: **<span style="color: red">Enhancing the reliability, efficiency, and usability of Bayesian population PBPK modeling</span>**

- Specific Aim 1: Develop, implement, and evaluate methodologies for parallelizing time-intensive calculations and enhancing a simulated tempering-based MCMC algorithm for Bayesian parameter estimation  
(.font120[**Revise algorithm in model calibration**])

.highlight[
- Specific Aim 2: Create, implement, and evaluate a robust **Global Sensitivity Analysis** algorithm to reduce PBPK model parameter dimensionality  
(.font120[**Parameter fixing**])
]  

- Specific Aim 3: Design, build, and test a user-friendly, open source computational platform for implementing an integrated approach for population PBPK modeling  
(.font120[**User friendly interface**])

---

# Parameter fixing in PBPK

.font75[
- Hsieh N-H, Reisfeld B, Bois FY and Chiu WA. 2018. [Applying a Global Sensitivity Analysis Workflow to Improve the Computational Efficiencies in Physiologically-Based Pharmacokinetic Modeling](https://www.frontiersin.org/articles/10.3389/fphar.2018.00588/full). Frontiers in Pharmacology 9:588.
- Hsieh et al. (Submitted) - pksensi: An R Package to Apply Global Sensitivity Analysis in Physiologically Based Kinetic Modeling
]
.center[
![:scale 70%](https://i.ibb.co/tqpDLrk/sensitivity-workflow.png)
]

---

# Parameter fixing in PBPK

.center[![](https://i.ibb.co/nkJ8nTQ/Workflow.png)]

---

# Uncertainty analysis - Flip-flop kinetics

.pull-left[
```{r eval=T}
library(pksensi)

# define parameter distributions
params <- c("F","KA","KE","V")
q <- c("qunif", "qunif", "qunif", "qnorm")
q.arg <- list(list(min = 0.8, max = 1),
              list(min = 0.5, max = 0.8),
              list(min = 0.1, max = 0.3),
              list(mean = 10, sd = 1))

# create parameter matrix and conduct simulation
x <- rfast99(params = params, n = 200, 
             q = q, q.arg = q.arg, rep = 20)
time <- seq(from = 0.01, to = 12.01, by = 0.5)
y <- solve_fun(x, model = FFPK, time = time, 
               vars = "output")
```
]

.pull-right[
```{r fig.height=5, dev='svg', eval=T}
pksim(y)
```
]

---

# Uncertainty analysis - PK model

.center[
```{r, echo=F, fig.height=5, dev='svg'}
par(mfrow=c(4,4),mar=c(0.8,0.8,0.8,0),oma=c(4,4,2,1), pch =".")
for (j in c("F","KA","KE","V")) {
  if ( j == "V") {
    plot(y$a[,1,j], ylab = "V")
  } else plot(y$a[,1,j], xaxt="n", ylab = "")
  for (i in 2:3) {
    if ( j == "V") {
      plot(y$a[,i,j], ylab = "", yaxt="n")  
    } else plot(y$a[,i,j], xaxt="n", yaxt="n", ylab = "")
  } 
  hist <- hist(y$a[,,j], plot=FALSE, 
               breaks=seq(from=min(y$a[,,j]), to=max(y$a[,,j]), length.out=20))
  barplot(hist$density, axes=FALSE, space=0, horiz = T, main = j) 
}
mtext("Model evaluation", SOUTH<-1, line=2, outer=TRUE)
```
]

---

# Sensitivity analysis - PK model

.center[
```{r, echo=F, fig.height=5, dev='svg'}
par(mfcol=c(4,4),mar=c(0.8,0.8,0,0),oma=c(4,4,2,1), pch = ".")
plot(x$a[,1,"F"], y$y[,1,"0.01",1], xaxt="n", main = "\nF")
plot(x$a[,1,"F"], y$y[,1,"2.01",1], xaxt="n")
plot(x$a[,1,"F"], y$y[,1,"6.01",1], xaxt="n")
plot(x$a[,1,"F"], y$y[,1,"12.01",1])
for (j in c("KA","KE","V")){
  for (k in c("0.01", "2.01", "6.01", "12.01")){
    if (k == "0.01") {
      plot(x$a[,1,j], y$y[,1,k,1], yaxt = "n", xaxt="n", main = paste0("\n", j))
    } else if (k == "12.01") {
      plot(x$a[,1,j], y$y[,1,k,1], yaxt = "n")
    } else plot(x$a[,1,j], y$y[,1,k,1], xaxt = "n", yaxt = "n")
  }
}
mtext("Parameter", SOUTH<-1, line=2, outer=TRUE)
mtext("Ccompartment", WEST<-2, line=2, outer=TRUE)
```
]

---

# Sensitivity analysis - PK model

```r
plot(y)
```

.center[
```{r fig.height=4.5, fig.width=9, dev='svg', eval=T, echo=F}
plot(y)
```
]


---

class: middle, center

--- Application ---
# If you have *known* "parameters"
# ------------------------------------>
# <font color="red"> Parameters / Model / Data</font>
# <------------------------------------
# If you have *known* "data" 
--- Calibration ---

---

</br>
</br>

## Currently, the Bayesian Markov chain Monte Carlo (MCMC) algorithm is an effective way to do population PBPK model calibration.   
## It is a powerful tool, Because...

.font150[
>It gives us the opportunity to understand and quantify the .font120["uncertainty"] and .font120["variability"] from individuals to .font150[population] through **data** and **model**.
]

---


# Frequentist vs. Bayesian

.pull-left[
![](https://i.ibb.co/YPRVnd1/Screenshot-from-2019-12-03-13-50-13.png)
]

.pull-right[
![](https://i.ibb.co/tPtbLmD/Screenshot-from-2019-12-03-13-49-53.png)
]

.footnote[
https://link.springer.com/article/10.3758/s13423-016-1221-4
]
---

# Bayes' rule

.font200[
$$ p(\theta|y) = \frac{p(\theta) p(y|\theta) }{p(y)}$$
]

$y$: **Observed data**

$\theta$: **Observed or unobserved parameter**

</br>

$p(\theta)$: *Prior distribution* of model parameter

$p(y|\theta)$: *Likelihood* of the experiment data given by a parameter vector

$p(\theta|y)$: *Posterior distribution*

$p(y)$: *Likelihood* of data

---

# Monty Hall Problem

> Suppose you’re on a game show, and you’re given the choice of three doors. Behind one door is a car, behind the others, goats. You pick a door, say number 1, and the host, who knows what’s behind the doors, opens another door, say number 3, which has a goat. He says to you, ”Do you want to pick door number 2?” Is it to your advantage to switch your choice of doors?

> Marilyn vos Savant. 1990. Ask Marilyn. *Parade Magazine*: 16.

.pull-left[
]
.pull-right[

```{R echo=F, fig.height=5.2, fig.width=9}
N <- 500
set.seed(7)
prize <- sample(1:3, N, replace = TRUE)
stay <- sample(1:3, N, replace = TRUE)
reveal <- rep(0, N)
change <- rep(0, N)
for(i in 1:N) {
  x <- c(1:3)[-c(prize[i], stay[i])]
  reveal[i] <- x[sample.int(length(x), size = 1)]
  change[i] <- c(1:3)[-c(reveal[i], stay[i])]
}
changewin <- ifelse(change == prize, 1, 0)
staywin <- ifelse(stay == prize, 1, 0)
change_perc <- mean(changewin)
stay_perc <- mean(staywin)
plot(cumsum(changewin) / c(1:N), main = "'Convergence' to True Winning Proportions",
     xlab = "Trial", ylab = "Win Percent", ylim = c(0, 1), col = "blue")
abline(h = 2/3)
points(cumsum(staywin) / c(1:N), type = "p", col = "red")
abline(h = 1/3)
legend("topright", legend = c("Switch to Other Door","Don't Switch"), pch = 1 , col = c(4,2))
```

]

---

# Frequentist vs. Bayesian

![](https://i.ibb.co/920t4Nt/Screenshot-from-2019-12-03-13-51-43.png)

.footnote[
https://link.springer.com/article/10.3758/s13423-016-1221-4
]

---

# Markov Chain Monte Carlo

.font120[
- **Metropolis-Hastings sampling algorithm**
]

The algorithm was named for Nicholas Metropolis (physicist) and Wilfred Keith Hastings (statistician). The algorithm proceeds as follows.

**Initialize**

1. Pick an initial parameter sets $\theta_{t=0} = \{\theta_1, \theta_2, ... \theta_n\}$

**Iterate**

1. *Generate*: randomly generate a candidate parameter state $\theta^\prime$ for the next sample by picking from the conditional distribution  $J(\theta^\prime|\theta_t)$
2. *Compute*:  compute the acceptance probability 
$A\left(\theta^{\prime}, \theta_{t}\right)=\min \left(1, \frac{P\left(\theta^{\prime}\right)}{P\left(\theta_{t}\right)} \frac{J\left(\theta_{t} | \theta^{\prime}\right)}{J\left(\theta^{\prime} | \theta_{t}\right)}\right)$
2. *Accept or Reject*:
  1. generate a uniform random number $u \in[0,1]$
  2. if $u \leq A\left(x^{\prime}, x_{t}\right)$ accept the new state and set $\theta_{t+1}=\theta^{\prime}$, otherwise reject the new state, and copy the old state forward $\theta_{t+1}=\theta_{t}$

???

Markov chain Monte Carlo is a general method based on drawing values of theta from approximate distributions and then correcting those draws to better approximate target posterior p(theta|y).

---

class:hide-logo
.center[
![:scale 90%](https://i.ibb.co/9hbLTb8/Screenshot-from-2019-12-04-06-21-26.png)
]

.footnote[https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=standard]

---

class: middle

.font200[
## The product of output is not ~~best-fit~~, but "prior" and "posterior".
]

---

# log-likelihood

The log-likelihood function was used to assess the **goodness-of-fit** of the model to the data ([Woodruff and Bois, 1993](https://www.sciencedirect.com/science/article/pii/0378427493901035?via%3Dihub), [Hsieh et al., 2018](https://www.frontiersin.org/articles/10.3389/fphar.2018.00588/full#B43))

$$L L=\sum_{i=1}^{N}-\frac{1}{2} \cdot \frac{\left(y_{i}-\widehat{y}_{i}\right)^{2}}{S_{j[i]}^{2}}-\frac{1}{2} \ln \left(2 \pi s_{j[i]}^{2}\right)$$

$N$: the total number of the data points 

$y_i$: experimental observed

$\hat{y}_i$: model predicted value

$j[i]$: data type of data point $i$

$S_{j[i]}^{2}$: the variance for data type $j$

---

# General workflow

### 1 Model constructing or translating

### 2 Verify modeling result

- **Compare with published result**
- **Mass balance** 

### 3 Uncertainty and sensitivity analysis

- **Morris elementary effects screening** 
- **Fourier amplitude sensitivity test**

### 4 Model calibration and validation

- **Markov chain Monte Carlo** 
  - Diagnostics (Goodness-of-fit, convergence)

---

# Probabilistic Modeling

.center[
![:scale 72%](https://ars.els-cdn.com/content/image/1-s2.0-S1740675717300373-gr1_lrg.jpg)
]

.footnote[https://doi.org/10.1016/j.ddmod.2017.08.001]

---

background-image: url(https://ars.els-cdn.com/content/image/1-s2.0-S0300483X10002623-gr5.jpg)
background-size: 500px
background-position: 70% 80% 

# Bayesian Population Model

**Individuals level**

$E$: Exposure  

$t$: Time  

$\theta$: Specific parameters  

$y$: condition the data

</br>

**Population level**

$\mu$: Population means

$\Sigma^2$: Population variances

$\sigma^2$: Residual errors

.footnote[https://doi.org/10.1016/j.tox.2010.06.007]

---


background-image: url(https://i.ibb.co/61ryV3d/Screenshot-from-2019-11-27-13-01-24.png)
background-size: 350px
background-position: 20% 90% 

# Related publication 

Bois et al. (1996) - [Population toxicokinetics of tetrachloroethylene](https://link.springer.com/article/10.1007%2Fs002040050284)  
Chiu and Bois (2006) - [Revisiting the population toxicokinetics of tetrachloroethylene](https://link.springer.com/article/10.1007/s00204-006-0061-9)    

.pull-right[
![:scale 70%](https://i.ibb.co/c2ghZ7m/Screenshot-from-2019-11-27-13-01-46.png)
]


---

background-image: url(https://ars.els-cdn.com/content/image/1-s2.0-S027323000600095X-gr1.jpg)
background-size: 330px
background-position: 20% 80% 

# Related publication 

.font75[
Hack et al. (2006) - [Bayesian population analysis of a harmonized physiologically based pharmacokinetic model of trichloroethylene and its metabolites](https://www.sciencedirect.com/science/article/pii/S027323000600095X)
]

.pull-left[]

.pull-right[
![:scale 55%](https://ars.els-cdn.com/content/image/1-s2.0-S027323000600095X-gr3.jpg)
]

---

class: hide-logo

.pull-left[

## Related publication

Chiu et al. (2009) - [Characterizing uncertainty and population variability in the toxicokinetics of trichloroethylene and metabolites in mice, rats, and humans using an updated database, physiologically based pharmacokinetic (PBPK) model, and Bayesian approach](https://www.sciencedirect.com/science/article/pii/S0041008X09003238)  

</br>
![:scale 85%](https://ars.els-cdn.com/content/image/1-s2.0-S0041008X09003238-gr3_lrg.jpg)  
.font75[Hierarchical population statistical model for mice, rats, and humans. ]
]

.pull-right[

![:scale 85%](https://ars.els-cdn.com/content/image/1-s2.0-S0041008X09003238-gr2.jpg)  
.font75[Overall structure of updated PBPK model for TCE and metabolites. ]
]

---

background-image: url(https://i.ibb.co/VHT9qZ3/chiu2019.jpg)
background-size: 500px
background-position: 50% 90% 

# Related publication 

- Characterizing PBPK parameters from individuals to population

- Evaluating population **variability** and parameter **uncertainty**

- Cross-species comparisons of metabolism in **risk assessment**

.footnote[
Chiu et al. 2009.  
https://doi.org/10.1016/j.taap.2009.07.032  
]

???

A brief summarizes the Bayesian approach in population PBPK modeling. We can use it to estimate the posterior parameter. Then used the parameter uncertainty to estimate the posterior population prediction and group-specific prediction. 

Based on this information we can compare the metabolism across experimental animals and human and further use this information in risk assessment.

---

background-image: url(https://i.ibb.co/tYDnPDb/chiu2014-2.png)
background-size: 500px
background-position: 75% 80% 

# Related publication 

**Inter-strain & inter-individual variability**

Chiu et al. (2014) - [Physiologically-Based Pharmacokinetic (PBPK) Modeling of Inter-strain Variability in Trichloroethylene Metabolism in the Mouse](https://ehp.niehs.nih.gov/doi/full/10.1289/ehp.1307623?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%3dpubmed)

<img src="https://i.ibb.co/DVWYytX/chiu2014.png" height="380px" />

???

It is an extensive study.

Previous animal studies mainly used single strain, B6C3F1 as a representative animal. But the issue to used B6C3F1 in extrapolation is the metabolism is very difference with the human. It had the highest rate of respiratory tract oxidative metabolism as compared to rats and humans. Also, it doesn't have representative variability in risk assessment.

So in this study, instead of B6 strain, it includes 16 inbreds to discuss inter-strain variability and use it to compare with the human inter-individual variability. 

Through the multi-strains model calibration and prediction, we can have consistent estimates of variability in human and mice

---

background-image: url(https://ars.els-cdn.com/content/image/1-s2.0-S0300483X18301781-gr2_lrg.jpg)
background-size: 300px
background-position: 70% 95%

# Recent study

Funding: **U.S. EPA (STAR RD83561202)** and **National Institutes of Health (F32 ES026005)**

Luo, Y.S., Hsieh, N.H., Soldatow, V.Y., Chiu, W.A. and Rusyn, I., 2018. [Comparative Analysis of Metabolism of Trichloroethylene and Tetrachloroethylene among Mouse Tissues and Strains](https://doi.org/10.1016/j.tox.2018.07.012). Toxicology, 409, pp.33-43.

<hr>

**Motivation**: Quantitative comparison of tissue- and strain-specific metabolism of TCE and PCE has not been performed

</br>

<img src= "https://ars.els-cdn.com/content/image/1-s2.0-S0300483X18301781-gr1.jpg" height="220px" />

???

---

</br>

</br>

Predicted disposition of **TCE (A)**, **PCE (B)**, and their respective metabolites in male B6C3F1/J, C57BL/6J, and NZW/LacJ mice.

.center[
![](https://ars.els-cdn.com/content/image/1-s2.0-S0300483X18301781-gr5.jpg)
]

.font70[
Pie charts are used to provide a relative comparison among various metabolites as predicted by the model in each strain.
]

???

This is the result of the disposition of TCE and PCE and their respective metabolites in mice strains. 
Pie charts are used to provide a relative comparison among various metabolites as predicted by the model in each strain. 
Most of each parent compound (TCE and PCE) remained unmetabolized until excretion
As you can see the disposition fractions are different across the mice strains. 
For to the glutathione conjugation metabolism, the overall flux to conjugation was less than 0.3% of the administered dose for both chemicals. 

---

# Recent study

Funding: **National Institutes of Health (P42 ES027704 and P42 ES ES005948)**

Luo, Y.S., Cichocki, J.A., Hsieh, N.H., Lewis, L., Wright, F.A., Threadgill, D.W., Chiu, W.A. and Rusyn, I., 2019. [Using Collaborative Cross Mouse Population to Fill Data Gaps in Risk Assessment: A Case Study of Population-Based Analysis of Toxicokinetics and Kidney Toxicodynamics of Tetrachloroethylene](https://doi.org/10.1289/EHP5105). Environmental Health Perspectives, 127(6), p.067011.

<hr>

**Background:**

- Interindividual variability in susceptibility remains poorly characterized for environmental chemicals such as tetrachloroethylene (PERC). 
- Development of population-based experimental models provide a potential approach to fill this critical need in human health risk assessment.

**Objectives:** 

- To better characterize the contribution of glutathione (GSH) conjugation to kidney toxicity of PERC and the degree of associated interindividual toxicokinetic (TK) and toxicodynamic (TD) variability by using the Collaborative Cross (CC) mouse population.

???

This is our following research. This study aim to apply the developed multicompartment PK model in human health risk assessment. In this study, we used in animal experiment result from CC mouse population to characterize metabolism–toxicity interactions and quantify the interindividual variability. Our main objective is ...

---

class:clear, hide-logo

.center[
![:scale 80%](https://i.ibb.co/KF8PLWy/Screenshot-from-2019-09-24-11-57-00.png)
]

.footnote[https://factor.niehs.nih.gov/2019/9/papers/dert/index.htm]

???

This paper was been selected as Papers of the Month. The brief summary of this study is 
- Mice exposed to PERC had lower kidney weight and more markers of kidney injury
- Inbred mice used in previous studies generally exhibited metabolism of PERC at the lower end of the overall distribution
- Default values that are generally used by the U.S. Environmental Protection Agency in human health risk assessments to adjust for population variation, the default values may protect 95% of the population but not the most sensitive individuals

---

class: hide-logo

.pull-left[
Interstrain Variability in Metabolism of PERC through Glutathione Conjugation Pathway

![:scale 70%](https://ehp.niehs.nih.gov/cms/attachment/9d640350-b940-4fc6-b40c-2cc96767ae3e/ehp5105_f4.jpg)

]

.pull-right[
Predicted disposition of PERC and its metabolites in CC mouse strains

![:scale 90%](https://ehp.niehs.nih.gov/cms/attachment/e8287e06-d8ab-423f-a58e-5332bd18523c/ehp5105_f6.gif)
]

---

class:clear

**Chemical-Specific Adjustment Factors for Population Variability and Risk Assessment**

![](https://i.ibb.co/f24zFvp/UF-table.png) 
<hr>
.center[![:scale 40%](https://i.ibb.co/WF2dr8S/UF.png)]

???

Based on the inter-strain estimation, we further used predicted disposition of PERC, TCA, and GSH conjugates across CC strains to calculate the chemical-specific adjustment factors for TK variability


---

# Related publication

**U.S. Food and Drug Administration** 

Enhancing the reliability, efficiency, and usability of Bayesian population PBPK modeling - Create, implement, and evaluate a robust Global Sensitivity Analysis algorithm to reduce PBPK model parameter dimensionality

<hr>

- Hsieh N-H, Reisfeld B, Bois FY and Chiu WA. 2018. [Applying a Global Sensitivity Analysis Workflow to Improve the Computational Efficiencies in Physiologically-Based Pharmacokinetic Modeling](https://www.frontiersin.org/articles/10.3389/fphar.2018.00588/full). Frontiers in Pharmacology 9:588.

- Bois et al. (Submitted) - Well tempered MCMC simulations for population pharmacokinetic models

- Hsieh et al. (Submitted) - pksensi: An R Package to Apply Global Sensitivity Analysis in Physiologically Based Kinetic Modeling

---

# Inter & intra- variability modeling

.center[
.pull-left[
**Inter-individual variability model**
<img src= "https://i.ibb.co/QHMSrbq/inter.png" height="450px" /> 
]
.pull-right[
**Inter- & intra-individual variability model**
<img src= "https://i.ibb.co/2tzxQCN/inter-intra.png" height="450px" />
]
]

---

# Calibration & evaluation

###  Prepare model and input files 
  - Need at least 4 chains in simulation

### Check convergence & graph the output result
  - **Parameter**, **log-likelihood of data**
  - Trace plot, density plot, correlation matrix, auto-correlation, running mean, ...
  - Gelman–Rubin convergence diagnostics

### Evaluate the model fit
  - Global evaluation
  - Individual evaluation 

---

# Simulation in GNU MCSim

## Monte Carlo simulations

- Perform repeated (stochastic) simulations across a randomly sampled region of the model parameter space.

**Used to:** Check possible simulation (under given parameter distributions) results before model calibration

</br>

## SetPoints simulation

- Solves the model for a series of specified parameter sets. You can create these parameter sets yourself or use the output of a previous Monte Carlo or MCMC simulation.

**Used to:** Posterior predictive check, Local/global sensitivity analysis

---

## Example - Linear model

.pull-left[
.code75[
```r
## linear.model.R ####
Outputs = {y}

# Model Parameters
A = 0; # 
B = 1;

CalcOutputs { y = A + B * t); }

End.
```
]
]

.pull-right[
.code75[
```r
## linear_mcmc.in.R ####
MCMC ("MCMC.default.out","", # name of output 
     "",           # name of data file
     2000,0,       # iterations, print predictions flag,
     1,2000,       # printing frequency, iters to print
     10101010);    # random seed (default )

Level {
  
  Distrib(A, Normal, 0, 2); # prior of intercept 
  Distrib(B, Normal, 1, 2); # prior of slope 
  
  Likelihood(y, Normal, Prediction(y), 0.05);
  
  Simulation {
    PrintStep (y, 0, 10, 1); 
    Data  (y, 0.01, 0.15, 2.32, 4.33, 4.61, 6.68, 
                7.89, 7.13, 7.27, 9.4, 10.0);
  }
}

End.
```
]
]

---

## Example - MCMC simulation

.pull-left[
.code75[
```{r message=F}
model <- "models/linear.model"
input <- "inputs/linear.mcmc.in"
set.seed(1111) 
out <- mcsim(model, input) 
head(out)
tail(out, 4)
```
]
]

.pull-right[
.code75[
```{r, fig.height=5, dev='svg'}
plot(out$A.1., type = "l", xlab = "Iteration", ylab = "")
lines(out$B.1., col = 2)
legend("topright", legend = c("Intercept", "Slope"), 
       col = c(1,2), lty = 1)
```
]
]

---

## Example - Posterior check

.pull-left[
.code75[
```{r, fig.height=5, dev='svg'}
plot(out$A.1., out$B.1., type = "b",
     xlab = "Intercept", ylab = "Slope")

```
]
]

.pull-right[
.code75[
```{r fig.height=5, dev='svg'}
str <- ceiling(nrow(out)/2) + 1
end <- nrow(out)
j <- c(str:end)
plot(out$A.1.[j], out$B.1.[j], type = "b",
     xlab = "Intercept", ylab = "Slope")
```
]
]

---

## Example - Posterior check

.pull-left[
.code50[
```{r fig.height=5, dev='svg'}
out$A.1.[j] %>% density() %>% plot(main = "Intercept")
plot.rng <- seq(par("usr")[1], par("usr")[2], length.out = 1000)
prior.dens <- do.call("dnorm", c(list(x=plot.rng), c(0,2)))
lines(plot.rng, prior.dens, lty="dashed")
```
]
]

.pull-right[
.code50[
```{r fig.height=5, dev='svg'}
out$B.1.[j] %>% density() %>% plot(main = "Slope")
plot.rng <- seq(par("usr")[1], par("usr")[2], length.out = 1000)
prior.dens <- do.call("dnorm", c(list(x=plot.rng), c(1,2)))
lines(plot.rng, prior.dens, lty="dashed")
```
]
]

---

## Example - Evaluation of prediction

.pull-left[
.code75[
```r
# Observed
x <- seq(0,10,1)
y <- c(0.0, 0.15, 2.32, 4.33, 4.61, 6.68, 
       7.89, 7.13, 7.27, 9.4, 10.0)

# Expected
dim.x <- ncol(out)
for(i in 1:11){
  out[,ncol(out)+1] <- out$A.1. + out$B.1.*x[i]
}

# Plot
plot(x, y, pch ="")
for(i in 1901:2000){
  lines(x, out[i,c((dim.x+1):ncol(out))],col="grey")
}
points(x, y)
```
]
]

.pull-right[
```{r echo=FALSE, fig.height=6, dev='svg'}
# Observed
x <- seq(0,10,1)
y <- c(0.01, 0.15, 2.32, 4.33, 4.61, 6.68, 
       7.89, 7.13, 7.27, 9.4, 10.0)

# Expected
dim.x <- ncol(out)
for(i in 1:11){
  out[,ncol(out)+1] <- out$A.1. + out$B.1.*x[i]
}

# plot
plot(x, y, pch ="")
for(i in 1901:2000){
  lines(x, out[i,c((dim.x+1):ncol(out))],col="grey")
}
points(x, y)
```
]

---

## Example - Evaluation of prediction

.pull-left[
.code75[
```r
# Use prediction from the last iteration
i <- 2000
Expected <- out[i, c((dim.x+1):ncol(out))] %>% 
  as.numeric()
Observed <- c(0.01, 0.15, 2.32, 4.33, 4.61, 6.68, 
              7.89, 7.13, 7.27, 9.4, 10.0)

# Plot
plot(Expected, Observed/Expected, pch='x')
abline(1,0)
```
]
]

.pull-right[
```{r echo=FALSE, fig.height=6, dev='svg'}
# Use prediction from the last iteration
i <- 2000
Expected <- out[i, c((dim.x+1):ncol(out))] %>% 
  as.numeric()
Observed <- c(0.01, 0.15, 2.32, 4.33, 4.61, 6.68, 
              7.89, 7.13, 7.27, 9.4, 10.0)

# Plot
plot(Expected, Observed/Expected, pch='x')
abline(1,0)
```
]

---

# Summary

.font200[
- In the real-word study, we need to consider the uncertainty (from different sources) and variability (inter or intra-individual data) to consider all possible scenarios.

- Bayesian statistics is a powerful tool to quantify the uncertainty and variability in pharmacokinetic modeling.

- The sensitivity analysis approch can provide the useful information of parameter impact on PBPK model.
]

---

# Hands on Exercise

## Task 1: Uncertainty analysis & Model calibration for simple PK model

.font150[
- In the previous exercise, we find that the predcited result can not used to describe the real cases. Therefore, we need to conduct the uncertainty analysis to figure out how to reset the model parameter.

- Use the parameter distributions that we test in uncertainty analysis and conduct MCMC simulation to do model calibration.
]

---

background-image: url(https://i.ibb.co/yn7tD14/Screenshot-from-2019-12-04-15-32-34.png)
background-size: 350px
background-position: 99% 80% 

# Hands on Exercise

## Task 2: Monte Carlo Simulation for PBPK model

- Reproduce the published Monte Carlo analysis result in Bois and Brochot (2016)*
  - Testing parameter include body mass (`BDM`), pulmonary flow (`Flow_pul`), partition coefficient of arterial blood (`PC_art`) and metabolism rate (`Kmetwp`)
- Construct the relationship between body mass and quantity in fat

.footnote[
[*] Bois F.Y., Brochot C. (2016) [Modeling Pharmacokinetics](https://link.springer.com/protocol/10.1007%2F978-1-4939-3609-0_3). In: Benfenati E. (eds) In Silico Methods for Predicting Drug Toxicity. Methods in Molecular Biology, vol 1425. Humana Press, New York, NY  
]

---

# Hands on Exercise

## Task 3: Reuild PBPK model in MCSim

- The Monte Carlo Simulation take a little bit longer with `ode` function in **deSolve** package. Therefore we want to improve the computational speed. Now, rewrite the R model code to **MCSim** and conduct Monte Carlo Simulation with the same parameter setting. The goal of this exercise is to compare the computational time and output (MCSim vs. R).

```r
Distrib (BDM, Normal, 73, 7.3);
Distrib (Flow_pul, Normal, 5, 0.5);
Distrib (PC_art, Normal, 2, 0.2);
Distrib (Kmetwp, Normal, 0.25, 0.025);
```

---

# Hands on Exercise

## Task 4: Sensitivity analysis

- The MCSim can provide faster computational speed than **deSolve**. Now, we can add additional parameters and see the relationship between body mass and quantity in fat changed. If we get a different result, which means there might have interaction between the parameters. The parameter values can refer from Bois (2013)*

.code75[
```r
Distrib (Pct_BDW_wp,    TruncLogNormal, 0.2, 1.2, 0.1,  0.35);
Distrib (Pct_Deadspace, TruncLogNormal, 0.4, 1.2, 0.23, 0.45);
Distrib (Pct_Flow_fat,  TruncLogNormal, 0.05,1.2, 0.03, 0.09);
Distrib (Pct_Flow_pp,   TruncLogNormal, 0.15,1.2, 0.06, 0.26);
Distrib (PC_pp,         TruncLogNormal, 0.7, 1.2, 0.4,  1.2);
Distrib (PC_wp,         TruncLogNormal, 0.7, 1.2, 0.4,  1.2);
```
]

.footnote[
[*] Bois F.Y. 2013. [Bayesian Inference](https://link.springer.com/protocol/10.1007/978-1-62703-059-5_25#Bib1). In: Reisfeld B., Mayeno A. (eds) Computational Toxicology. Methods in Molecular Biology (Methods and Protocols), vol 930. Humana Press, Totowa, NJ
]
